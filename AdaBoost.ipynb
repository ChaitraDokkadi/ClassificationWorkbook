{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import random\n",
    "\n",
    "def gini_index(samples, classes):\n",
    "    gini = 0.0\n",
    "    samples_count = float(sum([len(group) for group in samples]))\n",
    "    \n",
    "    for group in samples:\n",
    "        if float(len(group)) < 1.0:\n",
    "            continue\n",
    "        total_score = 0.0\n",
    "        for current_class in classes:\n",
    "            current_class_score = [row[-1] for row in group].count(current_class) / float(len(group))\n",
    "            total_score += current_class_score**2\n",
    "        gini += (1.0 - total_score) * (float(len(group)) / samples_count)\n",
    "    return gini\n",
    "\n",
    "def evaluate_best_split(data):\n",
    "    class_values = np.unique(data[:,-1])\n",
    "    \n",
    "    best_index = 10000\n",
    "    best_value = 10000\n",
    "    best_score = 10000\n",
    "    best_groups = None\n",
    "    \n",
    "    for index in range(len(data[0])-1):\n",
    "        for row in data:\n",
    "            left = []\n",
    "            right = []\n",
    "            for item in data:\n",
    "                if type(row[index]) is str:\n",
    "                    left.append(item) if item[index] == row[index] else right.append(item)\n",
    "                else:\n",
    "                    left.append(item) if item[index] <= row[index] else right.append(item)\n",
    "            ordered_groups = np.array(left), np.array(right)\n",
    "            \n",
    "            gini = gini_index(ordered_groups, class_values)\n",
    "            if gini < best_score:\n",
    "                best_index = index\n",
    "                best_value = row[index]\n",
    "                best_score = gini\n",
    "                best_groups = ordered_groups\n",
    "    node = {}\n",
    "    node['index'] = best_index\n",
    "    node['value'] = best_value\n",
    "    node['left'], node['right'] = best_groups\n",
    "    return node\n",
    "\n",
    "def splitting(node,depth):\n",
    "    left = node['left']\n",
    "    right = node['right']\n",
    "    if(left.size==0 or right.size==0):\n",
    "        classes = left[:,-1] if right.size == 0 else right[:,-1]\n",
    "    \n",
    "        node['left'] = max(classes, key = list(classes).count)\n",
    "        node['right'] = node['left']\n",
    "        return\n",
    "\n",
    "    if depth >= maximum_depth:\n",
    "        classes = left[:,-1]\n",
    "        node['left'] = max(classes, key = list(classes).count)\n",
    "        classes = right[:,-1]\n",
    "        node['right'] = max(classes, key = list(classes).count)\n",
    "        return\n",
    "    \n",
    "    if len(left) > 1:\n",
    "        node['left'] = evaluate_best_split(left)\n",
    "        splitting(node['left'],depth+1)\n",
    "    else:\n",
    "        classes = left[:,-1]\n",
    "        node['left'] = max(classes, key = list(classes).count)\n",
    "    \n",
    "    if len(right) > 1:\n",
    "        node['right'] = evaluate_best_split(right)\n",
    "        splitting(node['right'],depth+1)\n",
    "    else:    \n",
    "        classes = right[:,-1]\n",
    "        node['right'] = max(classes, key = list(classes).count)\n",
    "\n",
    "def get_decision_tree(train_data,depth):\n",
    "    root = evaluate_best_split(train_data)\n",
    "    splitting(root,depth)\n",
    "    return root\n",
    "\n",
    "def get_label(row,node):\n",
    "    if row[node['index']] >= node['value']:\n",
    "        return get_label(row,node['right']) if type(node['right']) is dict else node['right']\n",
    "    else:\n",
    "        return get_label(row,node['left']) if type(node['left']) is dict else node['left']\n",
    "        \n",
    "def get_labels(test_data,node):\n",
    "    labels = []\n",
    "    for row in test_data:\n",
    "        label = get_label(row,node)\n",
    "        labels.append(label)\n",
    "    return labels\n",
    "\n",
    "def get_labels_ada_boost(test_data,trees,alphas):\n",
    "    x = np.zeros(len(test_data))\n",
    "    for (m, a) in zip(trees, alphas):\n",
    "#         print(a)\n",
    "        labels = get_labels(test_data,m)\n",
    "        updated_labels = []\n",
    "        for label in labels:\n",
    "            y = -1 if (label == '0' or label == 0) else 1\n",
    "            updated_labels.append(y)\n",
    "        x += a * np.array(updated_labels) \n",
    "    return np.sign(x)\n",
    "\n",
    "def ada_Boost(train_data,m):\n",
    "    trees = []\n",
    "    alphas = []\n",
    "    \n",
    "    weights = np.ones(len(train_data)) / len(train_data)\n",
    "\n",
    "    while len(trees) < m:\n",
    "#         print(len(trees))\n",
    "        N = len(weights)\n",
    "        \n",
    "        new_train_data_indices = np.random.choice(N, size=N, replace=True, p=weights)\n",
    "        \n",
    "        new_train_data = train_data[new_train_data_indices]\n",
    "\n",
    "        tree = get_decision_tree(new_train_data,0)\n",
    "        predicted_labels = get_labels(train_data,tree)\n",
    "        \n",
    "        error = weights.dot(predicted_labels != train_data[:,-1])\n",
    "        \n",
    "        if error > 0.5:\n",
    "            continue\n",
    "            \n",
    "        alpha = 0.5 * (np.log((1 - error)/error))\n",
    "#         print(len(predicted_labels))\n",
    "#         print(len(train_data[:,-1]))\n",
    "        train_labels = train_data[:,-1]\n",
    "        \n",
    "        change = []\n",
    "        for index in range(len(train_labels)):\n",
    "            change.append(1 if train_labels[index] == predicted_labels[index] else -1)\n",
    "        change = np.array(change) \n",
    "\n",
    "        change = np.asarray(change)\n",
    "        weights *= np.exp(-alpha*change)\n",
    "        weights /= sum(weights)\n",
    "\n",
    "        trees.append(tree)\n",
    "        alphas.append(alpha)\n",
    "    \n",
    "    return trees,alphas\n",
    "\n",
    "file_name = \"project3_dataset1.txt\"\n",
    "# file_name = \"project3_dataset2.txt\"\n",
    "\n",
    "data = np.loadtxt(file_name, delimiter=\"\\t\",dtype='str')\n",
    "data = np.array(data)\n",
    "\n",
    "K = 10\n",
    "maximum_depth = 1\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "M = [10]\n",
    "K=10\n",
    "ten_fold_cross_valid = np.array_split(data, K)\n",
    "\n",
    "for m in M:\n",
    "    for i in range(K):\n",
    "        test_data=ten_fold_cross_valid[i]\n",
    "        train_data=np.array(np.vstack([x for index,x in enumerate(ten_fold_cross_valid) if index != i]))\n",
    "#         print(len(train_data))\n",
    "#         print(len(test_data))\n",
    "        \n",
    "        trees,alphas = ada_Boost(train_data,m)\n",
    "        \n",
    "        predicted_labels = get_labels_ada_boost(test_data,trees,alphas)\n",
    "        predicted_labels[predicted_labels == -1] = 0\n",
    "#         tree = get_decision_tree(train_data,0)\n",
    "#         predicted_labels = get_labels(test_data,tree)\n",
    "        \n",
    "#         print(test_data[:,-1])\n",
    "#         print(predicted_labels)\n",
    "        TP = FN = FP = TN = 0\n",
    "        for i in range(len(test_data[:,-1])):\n",
    "            if test_data[:,-1][i] == '1':\n",
    "                if predicted_labels[i] == 1:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FN +=1\n",
    "            else:\n",
    "                if predicted_labels[i] == 1:\n",
    "                    FP += 1\n",
    "                else:\n",
    "                    TN +=1\n",
    "#         print('TP', TP)\n",
    "#         print('FN', FN)\n",
    "#         print('FP', FP)\n",
    "#         print('TN', TN)\n",
    "        if TP + FN + FP + TN !=0:\n",
    "            accuracy.append(float(TP + TN)/(TP + FN + FP + TN))\n",
    "        if TP + FP !=0:\n",
    "            precision.append(float(TP)/(TP + FP))\n",
    "        if TP + FN !=0:\n",
    "            recall.append(float(TP)/(TP + FN))\n",
    "        if TP + FN + FP !=0:\n",
    "            f1.append(float(2 * TP) / ((2 * TP) + FN + FP))\n",
    "\n",
    "    print(\"Average accuracy  : \"+  str(sum(accuracy)*100/len(accuracy)))\n",
    "    print(\"Average precision : \"+  str(sum(precision)*100/len(precision)))\n",
    "    print(\"Average recall    : \"+  str(sum(recall)*100/len(recall)))\n",
    "    print(\"Average f_measure : \"+  str(sum(f1)*100/len(f1)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
